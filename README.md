# AI2-code
机器翻译：
1. (无用，可忽略)[Seq2Seq 机器翻译, 全程手写代码](https://www.bilibili.com/video/BV1hf4y1u7ez?p=2&vd_source=14b5aa0f75150f92a422f3d1987176ce)（视频）  
对应源码：[https://github.com/shouxieai/seq2seq_translation](https://github.com/shouxieai/seq2seq_translation)
<hr>

编码策略：
1. [BPE 算法原理及使用指南【深入浅出】](https://blog.csdn.net/a1097304791/article/details/122068153)
<hr>

解码策略：
1. [浅谈文本生成或者文本翻译解码策略](https://blog.csdn.net/HUSTHY/article/details/115028696)（附代码）
（包含贪心搜索greedy search，beam_search集束搜索，随机sampling，Top-K Sampling和Top-p (nucleus) sampling）
2. [Beam Search快速理解及代码解析](https://blog.csdn.net/qq_41466892/article/details/121119550)

<hr>

pytorch部分函数讲解：
1. [pytorch基础入门教程/一小时学会pytorch](https://blog.csdn.net/weixin_41070748/article/details/89890330)
2. [torch.argmax函数说明](https://blog.csdn.net/weixin_42494287/article/details/92797061)
3. [torch.multinomial()理解](https://blog.csdn.net/monchin/article/details/79787621)
4. [torch.topk与torch.sort用法](https://blog.csdn.net/weixin_43818631/article/details/121771760)
5. [剖析 | torch.cumsum维度详解](https://blog.csdn.net/songxiaolingbaobao/article/details/114580364)(累加)
6. [torch.cumsum() 和 torch.cumprod()](https://blog.csdn.net/qq_30122359/article/details/102955570)(累加和累乘)
7. [Python numpy pytorch 中的数据复制 copy deepcopy clone detach](https://blog.csdn.net/qq_40728667/article/details/122161029)
8. [【python基础】PyTorch中clone()、detach()](https://blog.csdn.net/dujuancao11/article/details/121563226)
9. [YDOOK：Pytorch教程：tensor 张量内各个值同时相加一个数](https://blog.csdn.net/weixin_42255190/article/details/121598429)
